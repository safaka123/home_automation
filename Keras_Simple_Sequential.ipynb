{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Kütüphanelerin ve veri setinin yüklenmesi (Çalıştırmak için öncelikle dosyanın Colab'ta bulunması gerekiyor. Soldaki panelden halledilebilir.)**"
      ],
      "metadata": {
        "id": "N74zW5EWpXw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7X-Kr9HqZWWT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = pd.read_csv('electrical_1.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns = dataset.columns.str.strip()\n",
        "dataset.drop(['Detector'], axis=1, inplace=True)\n",
        "\n",
        "x = dataset.drop(columns=[\"Status\", \"Time\", \"Reading ID\"])\n",
        "\n",
        "print(x)\n",
        "x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90_p7aLqaeLX",
        "outputId": "d28424ab-8cab-46a8-b9d5-f957b083047b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Humidity  Temperature  MQ139  TVOC  eCO2\n",
            "0         38.2         21.9     69     0   400\n",
            "1         38.2         21.9     69     0   400\n",
            "2         38.2         21.9     69     0   400\n",
            "3         38.2         21.9     68     0   400\n",
            "4         38.3         21.9     68     0   400\n",
            "...        ...          ...    ...   ...   ...\n",
            "1135      41.3         22.3    134  7020  6640\n",
            "1136      41.3         22.3    134  7115  7190\n",
            "1137      41.3         22.3    131  7261  6750\n",
            "1138      41.3         22.3    128  7110  5858\n",
            "1139      41.3         22.3    128  7144  6100\n",
            "\n",
            "[1140 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1140, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset[\"Status\"]\n",
        "print(y)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JDmspY6njlU",
        "outputId": "98e7c59b-28b7-4178-e7c6-d46231922634"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "1135    2\n",
            "1136    2\n",
            "1137    2\n",
            "1138    2\n",
            "1139    2\n",
            "Name: Status, Length: 1140, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1140,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "l5zVGEIEZbi8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train)\n"
      ],
      "metadata": {
        "id": "PvJK--dxbdt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "Dk6udq6IbiIH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(256, input_shape=(None, 5), activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(256, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "13Tb37mhbiKR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "3hNG-Z95biPW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train_encoded, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DRBG0oGbrLs",
        "outputId": "a4a50934-20b7-4977-91eb-42f81ad2416f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 2s 7ms/step - loss: 0.2900 - accuracy: 0.9178\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9507\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9507\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9583\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9583\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9616\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9561\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9572\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9550\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9561\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9572\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9627\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9638\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9518\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9638\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9518\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9529\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9583\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9572\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9605\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9792\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9671\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9605\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9682\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9638\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9759\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9649\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9704\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9693\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9737\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9726\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9803\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9759\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9803\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9846\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9715\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9836\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9737\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9693\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9715\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9572\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9616\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9715\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9792\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9737\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9660\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9682\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9572\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9638\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9594\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9649\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9748\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9649\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9704\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9594\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9660\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9825\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9836\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9693\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9572\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9660\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9638\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9627\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9770\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9671\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9715\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9726\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9715\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9781\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9737\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9792\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9803\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9792\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9682\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9485\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9550\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9737\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9792\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9550\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9671\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9781\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9704\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9748\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9792\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9792\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9737\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9792\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9770\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9770\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9737\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9748\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9759\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9737\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9715\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9693\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9759\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9737\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9781\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c3647f0edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_encoded = to_categorical(y_test)\n",
        "print(y_test_encoded)\n",
        "y_test_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnJFjGDZaPjW",
        "outputId": "81aab294-e0fe-47f5-be2b-03700e242068"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(228, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXEjTszVcb5h",
        "outputId": "32a4b8cc-eee6-4835-facb-50c04c2c1f02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9737\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03369789943099022, 0.9736841917037964]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('new_model.keras')"
      ],
      "metadata": {
        "id": "9eBtbrgJcgBT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"new_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQqRZgOsc-j-",
        "outputId": "59915db8-6585-4b59-8fb8-2b46ac78a1ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "#loaded_model = load_model(\"my_model.h5\")"
      ],
      "metadata": {
        "id": "9D-L8_6jct8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict(new_data)\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#New data için olan kısım diğer programlarda bulunabilir"
      ],
      "metadata": {
        "id": "YGhM-SbVdOkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}